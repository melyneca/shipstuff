{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ship_Classify_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjfX99UAe2SBB911FMFh15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melyneca/shipstuff/blob/main/Ship_Classify_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Önce uygun kütüphaneler yüklenir\n"
      ],
      "metadata": {
        "id": "ahS4WrT8Ti-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jNhBGwEyuNq6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip dosyası açılır ve extractall() ile dosyalar dışarı çıkarılır"
      ],
      "metadata": {
        "id": "kgepNgWuTupb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "# Zip file directory\n",
        "file_name = \"/content/archive (1).zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # extracting all the files\n",
        "    zip.extractall()"
      ],
      "metadata": {
        "id": "NqgKRvjSJDjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU kullanılabilir durumdayda GPU kullanılır, değilde CPU kullanılır"
      ],
      "metadata": {
        "id": "U8FYwPxi9EWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "U80icVMNrQ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip içindeki resimler dataset haline getirilir"
      ],
      "metadata": {
        "id": "bHXR9VD39SPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from skimage import io\n",
        "\n",
        "class ShipLoad(Dataset):\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    #Returns the lenght of the dataset\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "    image = io.imread(img_path)\n",
        "    \n",
        "    y_label = torch.tensor(int(self.annotations.iloc[index, 1])-1)\n",
        "\n",
        "    #Applies the transformation\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return (image, y_label)"
      ],
      "metadata": {
        "id": "mFQvXhSdMoLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelin öğrenebilmesi için resimlerin belli bir yapıda olması gerekir. Bu yüzden uygun transform fonksiyonları uygulanır\n",
        "Dataset içinde siyah-beyaz resimler de bulunduğu için, tüm resimleri siyah-beyaz bir şekilde işlemek daha verimli oldu"
      ],
      "metadata": {
        "id": "JiwMfOpe90Oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform= transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #The dataset contains grayscaled images. \n",
        "        #Making all the images grayscaled works better\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((128,128)),\n",
        "        transforms.ToTensor(),\n",
        "        #The images should be normalized, If not the calculations can not be made \n",
        "        transforms.Normalize((0.5),(0.2))\n",
        "        ])"
      ],
      "metadata": {
        "id": "SE1LT7gxXtTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elimde bulunan veri setinde sadece train set sınıflandırılmıştı. Doğru bir şekilde modeli test etmek için tüm sınıflandırılmış resimleri %80-%20 şeklinde böldüm"
      ],
      "metadata": {
        "id": "Vf9WrKYE-GOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "#Loads all labeled images, and splits it to test and train data\n",
        "data = ShipLoad('/content/train/train.csv', root_dir ='/content/train/images', transform = transform)\n",
        "train_set_size = int(len(data) * 0.8)\n",
        "test_set_size = len(data) - train_set_size\n",
        "train_set, test_set = random_split(data, [train_set_size, test_set_size])"
      ],
      "metadata": {
        "id": "FfvpcB16Q6gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total data: {len(data)}\")\n",
        "print(f\"Size of train data: {len(train_set)}\")\n",
        "print(f\"Size of test data: {len(test_set)}\")\n",
        "image,label = train_set[3]\n",
        "print(f\"Shape of one image: {image.shape}\")\n",
        "print(f\"Number of color channel: {image.shape[0]}\")\n",
        "print(f\"Widht and Height: ({image.shape[1]},{image.shape[1]})\")"
      ],
      "metadata": {
        "id": "ivrreFkO-CY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Cargo','Military','Carrier','Cruise','Tankers']\n",
        "print(f\"Class of ships: {classes}\")"
      ],
      "metadata": {
        "id": "_dei3tbnfxwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "fig = plt.figure(figsize=(11,11))\n",
        "\n",
        "#Prints random images from dataset\n",
        "for i in range(1,17):\n",
        "  id = random.randint(0,len(train_set))\n",
        "  images, label = train_set[id] \n",
        "  fig.add_subplot(4, 4, i)\n",
        "  plt.imshow(images.squeeze(), cmap=\"gray\")\n",
        "  plt.axis('off');\n",
        "  plt.title(classes[label]);\n"
      ],
      "metadata": {
        "id": "T0D1DWFcetX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoadder kullanılarak resimler batchler halinde yüklenir\n"
      ],
      "metadata": {
        "id": "Y2jT_JuDUGTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = DataLoader(dataset = train_set, batch_size= 32, shuffle= True)\n",
        "# The model have never seen the test images before. No need to shuffle\n",
        "test_data = DataLoader(dataset = test_set, batch_size= 32, shuffle= False)"
      ],
      "metadata": {
        "id": "GTGkEmW9RxYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, \n",
        "                      out_channels=20, \n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, \n",
        "                      padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=20, \n",
        "                      out_channels=15,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=15, \n",
        "                      out_channels=15, \n",
        "                      kernel_size = 3, \n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=15,\n",
        "                      out_channels=15, \n",
        "                      kernel_size = 3, \n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=(15*32*32), \n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv2(self.conv1(x))\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yccuB9gxknFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN = CNN(output_shape=5).to(device)"
      ],
      "metadata": {
        "id": "kRJsoDYwjgba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model:\\n{modelCNN}\")"
      ],
      "metadata": {
        "id": "IuhUcfwDC-1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=modelCNN.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "wlQGjvci9IVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100 \n",
        "    return acc"
      ],
      "metadata": {
        "id": "0sWCCXXMpMpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "ZEdLj0KZ9fcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  ### Training\n",
        "    \n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "    \n",
        "  # Add a loop to loop through training batches\n",
        "  for batch, (image, label) in enumerate(train_data):\n",
        "    \n",
        "    modelCNN.train() \n",
        "    image = image.to(device)\n",
        "    label = label.type(torch.long).to(device)\n",
        "         \n",
        "    # Forward pass\n",
        "    label_pred = modelCNN(image)\n",
        "\n",
        "    # Calculate loss \n",
        "    loss = loss_fn(label_pred, label)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=label, y_pred= label_pred.argmax(dim=1)) \n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer.step()\n",
        "    \n",
        "  if epoch%3 == 0:\n",
        "    train_acc = train_acc/len(train_data)\n",
        "    train_loss = train_loss/len(train_data)\n",
        "    print(f\"Train acc:{train_acc}\")\n",
        "    print(f\"Train loss:{train_loss}\")    "
      ],
      "metadata": {
        "id": "IQOTgmE69mPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test = 0\n",
        "acc_test = 0\n",
        "\n",
        "modelCNN.eval()\n",
        "with torch.inference_mode():\n",
        "  for image_test, label_test in test_data:\n",
        "        \n",
        "    image_test = image_test.to(device)\n",
        "    label_test = label_test.type(torch.long).to(device)\n",
        "    \n",
        "    label_pred = modelCNN(image_test)\n",
        "    \n",
        "    loss_test += loss_fn(label_pred, label_test)\n",
        "    \n",
        "    acc_test += accuracy_fn(y_true=label_test, y_pred=label_pred.argmax(dim=1))\n",
        "    \n",
        "    # Scale loss and acc\n",
        "  loss_test /= len(test_data)\n",
        "  acc_test /= len(test_data)\n",
        "\n",
        "  print(f\"test loss:{loss_test}\")\n",
        "  print(f\"test acc:{acc_test}\")"
      ],
      "metadata": {
        "id": "Tv2sEuhAK__T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}